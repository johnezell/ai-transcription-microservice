#!/usr/bin/env python3
"""
WhisperX Model Pre-download Script
Downloads essential models during Docker build to eliminate runtime downloads
"""

import whisperx
import torch
import os
import time

def download_models():
    """Download essential WhisperX models for fast startup"""
    print("=== WhisperX Model Pre-downloading Phase 1 ===")
    start_time = time.time()
    
    # Download models without device-specific optimizations during build
    # The runtime service will load them with optimal GPU settings
    device = 'cpu'  # Only for downloading - runtime will use GPU
    models_downloaded = []
    models_failed = []
    
    print(f"GPU available during build: {torch.cuda.is_available()}")
    print("Note: Models downloaded for CPU during build, runtime will use GPU when available")
    
    # Model download configurations
    models_to_download = [
        {
            'name': 'tiny',
            'type': 'whisperx',
            'description': 'WhisperX tiny model (fast preset)'
        },
        {
            'name': 'small', 
            'type': 'whisperx',
            'description': 'WhisperX small model (balanced preset)'
        },
        {
            'name': 'medium',
            'type': 'whisperx', 
            'description': 'WhisperX medium model (high quality preset)'
        },
        {
            'name': 'large-v3',
            'type': 'whisperx',
            'description': 'WhisperX large-v3 model (highest quality preset)'
        },
        {
            'name': 'en',
            'type': 'alignment',
            'description': 'English alignment model (universal)'
        }
    ]
    
    for model_config in models_to_download:
        try:
            model_name = model_config['name']
            model_type = model_config['type']
            description = model_config['description']
            
            print(f"ðŸ“¥ Pre-downloading {description}...")
            model_start = time.time()
            
            if model_type == 'whisperx':
                # Use float32 for CPU downloads (float16 not supported on CPU)
                compute_type = "float32" if device == "cpu" else "float16"
                model = whisperx.load_model(
                    model_name, 
                    device=device, 
                    compute_type=compute_type,
                    download_root='/app/models'
                )
                print(f"  Model loaded with compute_type={compute_type} on device={device}")
                del model
            elif model_type == 'alignment':
                align_model, metadata = whisperx.load_align_model(
                    model_name, 
                    device=device, 
                    model_dir='/app/models'
                )
                del align_model
            
            model_time = time.time() - model_start
            print(f"âœ… {description} downloaded in {model_time:.1f}s")
            models_downloaded.append(f"{model_type}-{model_name}")
            
        except Exception as e:
            error_msg = f"Failed to download {model_config['description']}: {str(e)}"
            print(f"âŒ {error_msg}")
            models_failed.append(error_msg)
    
    # Clean up memory
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # Summary
    total_time = time.time() - start_time
    print(f"\n=== Pre-download Summary ===")
    print(f"âœ… Downloaded: {models_downloaded}")
    if models_failed:
        print(f"âŒ Failed: {models_failed}")
    print(f"â±ï¸  Total time: {total_time:.1f}s")
    print(f"ðŸŽ¯ Runtime model loading will now be ~10x faster!")
    print("=" * 50)
    
    return len(models_downloaded), len(models_failed)

if __name__ == "__main__":
    downloaded, failed = download_models()
    
    if failed > 0:
        print(f"WARNING: {failed} models failed to download")
        print("Container will fall back to runtime downloads for failed models")
    else:
        print("SUCCESS: All essential models pre-downloaded!")
    
    # Don't fail the build if some models fail - just warn
    print("Model pre-download script completed") 